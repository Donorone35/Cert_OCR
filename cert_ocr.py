# -*- coding: utf-8 -*-
"""Cert_OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yNNLgWuXe8hnGunMxKOFhz3wgl12bmta
"""

pip install pytesseract pillow opencv-python-headless pdf2image python-dateutil requests

!apt-get install -y poppler-utils

# Single-file OCR extractor tuned for semester grade report style certificates.
# Outputs JSON with DB-friendly fields.

import io
import os
import re
import json
import hashlib
import requests
from typing import List, Dict, Any, Optional

from PIL import Image
import pytesseract
from pytesseract import Output
import cv2
import numpy as np
from pdf2image import convert_from_bytes
from dateutil import parser as dateparser

# Regex patterns for parsing
YEAR_PATTERN = re.compile(r"\b(20\d{2})\b")
ROLL_PATTERN = re.compile(r"^\d{6,}$")

def compute_sha256_bytes(b: bytes) -> str:
    import hashlib
    return hashlib.sha256(b).hexdigest()

def load_file_to_pil(path_or_bytes: Any) -> List[Image.Image]:
    """
    Accepts:
      - path string for PNG/JPG/GIF/PDF
      - bytes (PDF bytes or image bytes)
    Returns list of PIL.Image objects (pages). We take first page for certificates.
    """
    images = []
    if isinstance(path_or_bytes, (bytes, bytearray)):
        # try pdf first
        try:
            imgs = convert_from_bytes(path_or_bytes, dpi=300)
            return imgs
        except Exception:
            # fallback to image
            return [Image.open(io.BytesIO(path_or_bytes)).convert("RGB")]
    elif isinstance(path_or_bytes, str):
        if path_or_bytes.lower().endswith('.pdf'):
            with open(path_or_bytes, 'rb') as f:
                pdf_bytes = f.read()
            imgs = convert_from_bytes(pdf_bytes, dpi=300)
            return imgs
        else:
            img = Image.open(path_or_bytes).convert("RGB")
            return [img]
    else:
        raise ValueError("Unsupported input type for load_file_to_pil")

def pil_to_cv2(img: Image.Image) -> np.ndarray:
    arr = np.array(img)
    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)

def preprocess_for_ocr_cv2(img_bgr: np.ndarray) -> np.ndarray:
    """
    Preprocessing to improve OCR: grayscale, resize if small, denoise, adaptive threshold.
    """
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    # Upscale small images
    if max(h, w) < 1000:
        scale = 1000 / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        gray = cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
    # Denoise
    denoised = cv2.fastNlMeansDenoising(gray, None, h=10)
    # Adaptive threshold to get good contrast for text
    try:
        th = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, 31, 11)
    except Exception:
        th = denoised
    return th

def ocr_image_to_text(pil_img: Image.Image) -> Dict[str, Any]:
    """
    Run pytesseract OCR and return useful outputs.
    """
    cv2_img = pil_to_cv2(pil_img)
    pre = preprocess_for_ocr_cv2(cv2_img)
    pil_pre = Image.fromarray(pre)
    # get structured data (useful if needed)
    ocr_data = pytesseract.image_to_data(pil_pre, output_type=Output.DICT)
    # combine words into lines as OCR output string
    n = len(ocr_data['text'])
    lines = []
    current_line = []
    last_block = None
    for i in range(n):
        txt = ocr_data['text'][i].strip()
        if not txt:
            # when empty text, flush line if exists
            if current_line:
                lines.append(" ".join(current_line))
                current_line = []
            continue
        current_line.append(txt)
        # Heuristic: if end of line (level data could be used), but simple logic:
        if (i+1 < n and ocr_data['line_num'][i] != ocr_data['line_num'][i+1]) or (i == n-1):
            lines.append(" ".join(current_line))
            current_line = []
    raw_text = "\n".join(lines)
    # Also full text fallback
    full_text = pytesseract.image_to_string(pil_pre)
    return {"raw_text": raw_text, "full_text": full_text, "ocr_data": ocr_data}

# -------------------
# Parsing rules (tailored to the provided sample)
# -------------------

def normalize_number(val: str) -> float:
    """
    Fix common OCR issues: misplaced/missing decimal points.
    - '841' -> 8.41 (for CGPA)
    - '110' -> 1,110 (already handled earlier by removing commas)
    """
    # If it's clearly > 10 and we expect a GPA (0‚Äì10), insert decimal
    if val.isdigit() and int(val) > 10:
        if len(val) == 3:
            return float(val[0] + "." + val[1:])
        elif len(val) == 2:
            return float(val[0] + "." + val[1:])
    return float(val)


def parse_semester_report_text(raw_text: str) -> Dict[str, Any]:
    """
    Improved parser for KIIT-style semester grade reports.
    Extracts key fields and course details robustly.
    """
    lines = [ln.strip() for ln in raw_text.splitlines() if ln.strip()]
    joined = "\n".join(lines)
    out: Dict[str, Any] = {
        "student_name": None,
        "roll_number": None,
        "registration_number": None,
        "programme": None,
        "year_of_admission": None,
        "semester": None,
        "courses": [],  # list of {code, name, credits, grade}
        "remarks": None,
        "sgpa": None,
        "cgpa": None,
        "cumulative_credits": None,
        "raw_text_hash": compute_sha256_bytes(joined.encode('utf-8'))
    }

    # --- 1. Year of admission ---
    for ln in lines[:20]:
        if "YEAR OF ADMISSION" in ln.upper():
            m = YEAR_PATTERN.search(ln)
            if m:
                out["year_of_admission"] = m.group(0)
            break

   # --- 2. Student name, roll, reg, semester ---
    for i, ln in enumerate(lines):
        if "STUDENT" in ln.upper() and "NAME" in ln.upper():
            if i + 1 < len(lines):
                candidate = lines[i + 1]
                tokens = candidate.split()
                # Extract name until first numeric token
                name_parts = []
                for t in tokens:
                    if t.isdigit() or ROLL_PATTERN.match(t):
                        break
                    name_parts.append(t)
                if name_parts:
                    out["student_name"] = " ".join(name_parts).strip()

                nums = [t for t in tokens if ROLL_PATTERN.match(t)]
                if len(nums) >= 2:
                    out["roll_number"] = nums[0]
                    out["registration_number"] = nums[1]
                elif len(nums) == 1:
                    out["roll_number"] = nums[0]

                # Semester (e.g., "6th")
                m = re.search(r"\b(\d+(st|nd|rd|th))\b", candidate, re.IGNORECASE)
                if m:
                    out["semester"] = m.group(1)
            break

    # --- 3. Programme ---
    for ln in lines:
        if "PROGRAMME" in ln.upper():
            parts = ln.split(":", 1)
            if len(parts) > 1:
                out["programme"] = parts[1].strip()
            else:
                idx = lines.index(ln)
                if idx + 1 < len(lines):
                    out["programme"] = lines[idx + 1]
            break

    # --- 4. Remarks ---
    for ln in lines:
        if ln.upper().startswith("REMARK"):
            if "-" in ln:
                out["remarks"] = ln.split("-", 1)[1].strip()
            else:
                idx = lines.index(ln)
                if idx + 1 < len(lines):
                    out["remarks"] = lines[idx + 1]
            break

    # --- 5. Courses ---
    start_idx = None
    for i, ln in enumerate(lines):
        if "COURSE" in ln.upper() and ("NUMBER" in ln.upper() or "NAME" in ln.upper()):
            start_idx = i + 1
            break

    end_idx = None
    for i, ln in enumerate(lines):
        if "REMARK" in ln.upper() or "PERFORMANCE" in ln.upper():
            end_idx = i
            break

    if start_idx is not None:
        chunk = lines[start_idx:end_idx] if end_idx else lines[start_idx:start_idx + 40]
        for ln in chunk:
            m = re.match(r"([A-Z]{2,4}\d{3,5})\s+(.+?)\s+(\d{1,2})\s+([A-O])$", ln)
            if m:
                code, name, credits, grade = m.groups()
                out["courses"].append({
                    "course_code": code,
                    "course_name": name.strip(),
                    "credits": int(credits),
                    "grade": grade
                })

    # --- 6. Performance (SGPA, CGPA, cumulative credits) ---
    perf_idx = None
    for i, ln in enumerate(lines):
        if "CURRENT SEMESTER PERFORMANCE" in ln.upper():
            perf_idx = i
            break

    if perf_idx is not None:
        # Look at the next 2-3 lines after the header
        for j in range(perf_idx, min(perf_idx + 6, len(lines))):
          row = re.sub(r"[^\d\.\s,]", " ", lines[j])  # keep digits, dot, comma, space
          parts = [p.replace(",", "") for p in row.split() if re.search(r"\d", p)]
          # Expecting exactly 6 parts
          if len(parts) >= 6:
             out["credits"] = int(parts[0])
             out["credit_index"] = int(parts[1])
             out["sgpa"] = normalize_number(parts[2])
             out["cumulative_credits"] = int(parts[3])
             out["cumulative_credit_index"] = int(parts[4])
             out["cgpa"] = normalize_number(parts[5])
             break

    # --- 7. Final cleanup ---
    for k, v in out.items():
        if isinstance(v, str):
            out[k] = re.sub(r"\s+", " ", v).strip() if v else None

    return out


# -------------------
# Main runner
# -------------------

def get_public_ip(timeout=5) -> Optional[str]:
    """
    Attempt to get public IP (works in Colab if internet is allowed).
    """
    try:
        resp = requests.get('https://api.ipify.org?format=text', timeout=timeout)
        if resp.status_code == 200:
            return resp.text.strip()
    except Exception:
        return None
    return None

def extract_from_file(path_or_bytes: Any) -> Dict[str, Any]:
    pil_pages = load_file_to_pil(path_or_bytes)
    # take first page
    pil_img = pil_pages[0]
    # compute image hash
    buf = io.BytesIO()
    pil_img.save(buf, format='PNG')
    png_bytes = buf.getvalue()
    doc_hash = compute_sha256_bytes(png_bytes)

    # OCR
    ocr_res = ocr_image_to_text(pil_img)
    raw_text = ocr_res.get('raw_text') or ocr_res.get('full_text') or ""

    # Parse fields
    parsed = parse_semester_report_text(raw_text)
    parsed['document_image_hash'] = doc_hash
    parsed['ocr_engine'] = 'pytesseract'
    parsed['_raw_text'] = raw_text[:5000]  # truncated raw text in output (for debugging)

    return parsed

def main(input_path: str):
    print("Processing:", input_path)
    # Read bytes or path
    if input_path.lower().endswith('.pdf'):
        with open(input_path, 'rb') as f:
            b = f.read()
        parsed = extract_from_file(b)
    else:
        parsed = extract_from_file(input_path)

    # add env metadata
    parsed['_meta'] = {
        'public_ip': get_public_ip(),
        'processor': 'ocr_certificate_extractor.py'
    }

    # print pretty JSON
    print(json.dumps(parsed, indent=2, ensure_ascii=False))

    # save JSON file
    out_fn = os.path.splitext(os.path.basename(input_path))[0] + '_extracted.json'
    with open(out_fn, 'w', encoding='utf-8') as fw:
        json.dump(parsed, fw, indent=2, ensure_ascii=False)
    print("Saved result to", out_fn)

from google.colab import files

while True:
    print("\nüìÅ Upload a PDF/PNG/JPG certificate (or type 'exit' to stop)...")
    uploaded = files.upload()

    if not uploaded:
        print("No file uploaded. Exiting...")
        break

    filename = list(uploaded.keys())[0]
    if filename.lower() == "exit":
        break

    print(f"‚úÖ File uploaded: {filename}")

    # 1Ô∏è‚É£ Run the full OCR ‚Üí Parsing pipeline
    parsed = extract_from_file(filename)

    # 2Ô∏è‚É£ Add environment metadata
    parsed['_meta'] = {
        'public_ip': get_public_ip(),
        'processor': 'ocr_certificate_extractor.py'
    }

    # 3Ô∏è‚É£ Save parsed JSON
    json_filename = os.path.splitext(filename)[0] + "_extracted.json"
    with open(json_filename, 'w', encoding='utf-8') as fw:
        json.dump(parsed, fw, indent=2, ensure_ascii=False)

    print(f"‚úÖ JSON extracted and saved as: {json_filename}")
    files.download(json_filename)
    print("üì• Download started...")

    # 4Ô∏è‚É£ Ask if user wants to process another
    cont = input("Do you want to process another file? (y/n): ").strip().lower()
    if cont != 'y':
        print("üëã Exiting OCR loop.")
        break

